{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847655b0-2292-421e-bd93-0f1fb12184c4",
   "metadata": {},
   "source": [
    "# Annotation Process Overview\n",
    "\n",
    "During our project, we embarked on annotating the metropolitan areas of 1,000 universities from our corpus. This initial step involved identifying the specific metropolitan area for each university. Subsequently, we employed a Python script named `cities_gdp_population_scraper.py` to scrape Wikipedia for the population and GDP data of major metropolitan areas worldwide. The next phase entailed matching this scraped data with the metropolitan areas we had annotated to retrieve relevant statistics for our annotated locations. Based on the data acquired, we further annotated each university's entry with additional criteria: City Size, Type of Institution, Year of Institution's History, Economic Development Level, and Country Development Level.\n",
    "\n",
    "## Annotation Format\n",
    "The annotation format we used is \"one-token-per-line CSV,\" where each line represents a university. This format maps one university from our corpus to a single annotation line, comprising the university type, year of institution's history, its metropolitan area, the size of this area, the economic development level of the area, and the country's development level.\n",
    "\n",
    "## City Size Annotation\n",
    "\n",
    "The city size was classified based on population numbers into the following categories:\n",
    "\n",
    "- **Small:** Population less than 50,000\n",
    "- **Medium:** Population between 50,000 and 1,000,000\n",
    "- **Large:** Population between 1,000,000 and 5,000,000\n",
    "- **Extra Large:** Population greater than 5,000,000\n",
    "\n",
    "## Type of Institution Annotation\n",
    "\n",
    "Institutions were categorized as either Public or Private based on their funding and administration:\n",
    "\n",
    "- **Public:** Funded and administered by government bodies.\n",
    "- **Private:** Operated independently of government, with funding from tuition, donations, and private sources.\n",
    "\n",
    "## Year of Institution's History Annotation\n",
    "\n",
    "The age of each institution was annotated as follows:\n",
    "\n",
    "- **Young:** Less than 100 years since establishment.\n",
    "- **Old:** Between 100 and 500 years since establishment.\n",
    "- **Historic:** More than 500 years since establishment.\n",
    "\n",
    "## Economic Development Level Annotation\n",
    "\n",
    "This category was annotated based on GDP per capita (in USD) and divided into ranges that were not specified in your summary. Presumably, these ranges help classify the economic development level of the metropolitan area.\n",
    "\n",
    "## Country Development Level Annotation\n",
    "\n",
    "Based on the World Bank's classification, countries were categorized into:\n",
    "\n",
    "- **Developed Countries:** Nations with high levels of income, industrialization, and sophisticated infrastructure and services.\n",
    "- **Developing Countries:** Nations with lower income levels, varying degrees of industrialization, with some focusing on agriculture and textiles.\n",
    "\n",
    "## Challenges\n",
    "\n",
    "During the annotation process, we encountered several challenges that impacted the quantity and quality of our annotations. One significant challenge was inconsistencies in the data availability on Wikipedia for certain metropolitan areas. This inconsistency sometimes made it difficult to match the scraped data with our annotated metropolitan areas accurately, potentially affecting the reliability of our data.\n",
    "\n",
    "Additionally, the manual process of matching data could introduce human errors, leading to inaccuracies in the annotations. Such challenges were addressed through cross-verification where possible, but they highlight the limitations of relying on publicly available data and manual annotation processes.\n",
    "\n",
    "Despite these challenges, we strived to maintain high standards of accuracy and reliability in our annotations, ensuring that our dataset serves as a robust foundation for further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
